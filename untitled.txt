for current_value_of_stringency_weight in np.arange(-1e-3, -1e-4, 1e-5):
    betas = time_varying_beta(optimal_beta, current_value_of_stringency_weight, stringency_moves)
    r0 = betas/optimal_gamma

    df["S_modelled_fakemoves"] = store_S_fakemoves
    df["I_modelled_fakemoves"] = store_I_fakemoves
    df["R_modelled_fakemoves"] = store_R_fakemoves
    df["r_eff_actual_fakemoves"] = r0 * df["S_modelled_fakemoves"]/df["N"]
    first_time_r_eff_1 = next((t for t, r_eff in zip(df.index, df['r_eff_actual_fakemoves']) if r_eff <= 1), None)
    print(current_value_of_stringency_weight, first_time_r_eff_1)
    
    # this is strange because there's a sharp inflection in the model, if the stringency is greater than -0.0002999999999999982
    # r_eff day is zero and below that it jumps to 701 directly. This should probably be a little more 
    # smoother so that the effect of stringency 

how do I acknowledge this in the following model:

def deriv(y, t, N, beta, gamma):
    S, I, R = y
    dSdt = -beta * S * I / N
    dIdt = beta * S * I / N - gamma * I
    dRdt = gamma * I
    return dSdt, dIdt, dRdt

def compute_cost(data, predictions):
    n = len(data)
    return (100 / n) * np.sum(np.abs((data - predictions) / data))

def compute_cost(data, predictions):
    return np.sum(np.square(data - predictions))

def compute_cost(data, predictions):
    return np.abs(data - predictions).mean()

def integrate_system(params, y0, t, N):
    beta, gamma = params
    result = odeint(deriv, y0, t, args=(N, beta, gamma))
    return result

def objective_function(params, y0, t, N):
    predictions = integrate_system(params, y0, t, N)
    S, I, R = predictions.T
    cost = (compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R))
    return cost

def deriv_2(y, t, N, beta_array, gamma):
    S, I, R = y
    t = min(int(t), len(beta_array) - 1)
    dSdt = -beta_array[t] * S * I / N
    dIdt = beta_array[t] * S * I / N - gamma * I
    dRdt = gamma * I
    return dSdt, dIdt, dRdt
    
def time_varying_beta(optimal_beta, stringency_weight, stringency_index):
    beta = optimal_beta + (stringency_weight * stringency_index)
    return beta

def objective_function_2(params, y0, t, N, df, gamma, all_stringencies):
    stringency_weight = params[0]
    
    beta_array = time_varying_beta(optimal_beta, stringency_weight, all_stringencies)
    
    predictions = odeint(deriv_2, y0, t, args=(N, beta_array, gamma))
    S, I, R = predictions.T
    
    cost = compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R)
    return costs

# Set initial values
initial_guess_for_stringency_weight = [0.01]
days_difference = (max(df['date']) - min(df['date'])).days
t = np.linspace(0, days_difference, days_difference + 1)
current_stringency = df['stringency_index'].values

# Perform the optimization
result = minimize(
    objective_function_2,
    initial_guess_for_stringency_weight,
    args=(y0, t, N, df, optimal_gamma, current_stringency),
    method='Nelder-Mead',
)

optimal_stringency_weight = result.x[0]
print(f"Optimal stringency weight: {optimal_stringency_weight}")



def objective_function_2(params, y0, t, N, df, gamma, all_stringencies):
    stringency_weight = params[0]
    
    beta_array = time_varying_beta(optimal_beta, stringency_weight, all_stringencies)
    
    predictions = odeint(deriv_2, y0, t, args=(N, beta_array, gamma))
    S, I, R = predictions.T
    
    # Add a term to the cost function that penalizes sharp changes in stringency measures
    stringency_change_penalty = np.sum(np.abs(np.diff(beta_array)))
    
    cost = compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R) + stringency_change_penalty
    return cost