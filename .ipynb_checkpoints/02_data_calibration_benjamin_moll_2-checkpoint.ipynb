{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "np.random.seed(seed=0)\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "# plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# sns.set_style(\"whitegrid\", rc={'font.family': 'Times New Roman', 'font.size': 16})\n",
    "sns.set_style(\"whitegrid\", rc={'font.size': 16})\n",
    "\n",
    "from constants import LOCATION_CHOOSEN, LOCATION_CHOOSEN_2, OUTPUT_DIR, DATA_CACHE_DIR, OPTIMAL_VALUES_FILE, STRINGENCY_BASED_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9bcbb8",
   "metadata": {},
   "source": [
    "- Susceptible (S): This should ideally be the total population minus the total cases. So, your calculation seems correct here. However, it's important to note that 'total_cases' includes both currently infected individuals and those who have recovered or died. Therefore, a more accurate calculation might be `df['S'] = df['population'] - df['total_cases']`.\n",
    "\n",
    "- Infected (I): This should be the current active cases, not the total cases. You might need to calculate this as `df['I'] = df['total_cases'] - df['total_deaths'] - df['people_fully_vaccinated']`.\n",
    "\n",
    "- Recovered (R): This should include people who have recovered from the disease and those who are vaccinated. If your dataset includes a 'total_recovered' column, you could use that. If not, you might need to estimate it. You could potentially use `df['R'] = df['people_fully_vaccinated'] + df['total_deaths']` (assuming that all who are not currently infected and have not been vaccinated have recovered).\n",
    "\n",
    "Please note that these are just suggestions and the actual implementation might vary based on the specific details and assumptions of your model. Also, this model does not take into account the natural birth and death in the population. It's a simple model and might not fully capture the complexities of an actual outbreak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca969fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(DATA_CACHE_DIR, LOCATION_CHOOSEN + \"_merged_data.csv\")\n",
    "if os.path.exists(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    df = pd.read_excel(\"owid-covid-data.xlsx\")\n",
    "    df = df.loc[df['iso_code'] == LOCATION_CHOOSEN]\n",
    "    df.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3361c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = date(2020, 3, 1)\n",
    "end_date = date(2020, 10, 20)\n",
    "delta = timedelta(days=1)\n",
    "while start_date <= end_date:\n",
    "    date_str = start_date.strftime(\"%Y%m%d\")\n",
    "    data_path_worldometer = os.path.join(DATA_CACHE_DIR, \"worldometer\", date_str + \".csv\")\n",
    "    if os.path.exists(data_path_worldometer):\n",
    "        worldometer_df = pd.read_csv(data_path_worldometer)\n",
    "        date_data = \"\"\n",
    "        total_cases = 0\n",
    "        total_recovered = 0\n",
    "        try:\n",
    "            worldometer_df_specified_location = worldometer_df.loc[(worldometer_df[\"Country,Other\"].str.lower() == LOCATION_CHOOSEN_2.lower())]\n",
    "            date_data = date_str[:4] + \"-\" + date_str[4:6] + \"-\" + date_str[6:]\n",
    "            total_cases = worldometer_df_specified_location[\"TotalCases\"].item()\n",
    "            total_recovered = worldometer_df_specified_location[\"TotalRecovered\"].item()\n",
    "        except:\n",
    "            print(\"COLUMNS NAMES CHANGED: \", data_path_worldometer)\n",
    "            worldometer_df_specified_location = worldometer_df.loc[(worldometer_df[\"Country, Other\"].str.lower() == LOCATION_CHOOSEN_2.lower())]\n",
    "            date_data = date_str[:4] + \"-\" + date_str[4:6] + \"-\" + date_str[6:]\n",
    "            total_cases = worldometer_df_specified_location[\"Total Cases\"].item()\n",
    "            total_recovered = worldometer_df_specified_location[\"Total Recovered\"].item()\n",
    "        print(date_data, total_cases, total_recovered)\n",
    "    else:\n",
    "        print(data_path_worldometer, \"DOES NOT EXIST -- COLLECT DATA MANUALLY\")\n",
    "    start_date += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d917f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "# creating new columns\n",
    "df['N'] = df['population']\n",
    "df['S'] = df['population'] - (df['total_cases'] + df['people_fully_vaccinated'])\n",
    "df['I'] = df['total_cases']\n",
    "df['R'] = df['people_fully_vaccinated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5a0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outlier(data):\n",
    "    # find q1 and q3 values\n",
    "    q1, q3 = np.percentile(sorted(data), [25, 75])\n",
    " \n",
    "    # compute IRQ\n",
    "    iqr = q3 - q1\n",
    " \n",
    "    # find lower and upper bounds\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    " \n",
    "    outliers = [x for x in data if x <= lower_bound or x >= upper_bound]\n",
    " \n",
    "    return outliers\n",
    "\n",
    "print(detect_outlier(df['S']), detect_outlier(df['I']), detect_outlier(df['R']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11eddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(df['date'], df['S'], label='S')\n",
    "plt.plot(df['date'], df['I'], label='I')\n",
    "plt.plot(df['date'], df['R'], label='R')\n",
    "plt.title('COVID-19 Metrics Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"metrics_over_time_\" + LOCATION_CHOOSEN + \".png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ebcc45",
   "metadata": {},
   "source": [
    "## Without Lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90883616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(y, t, N, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I / N\n",
    "    dIdt = beta * S * I / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "def compute_cost(data, predictions):\n",
    "    # mse\n",
    "    return np.square(data - predictions).mean()\n",
    "\n",
    "def compute_cost(data, predictions):\n",
    "    # mae\n",
    "    return np.abs(data - predictions).mean()\n",
    "\n",
    "def compute_cost(data, predictions, delta=1.0):\n",
    "    # Huber loss\n",
    "    residual = np.abs(data - predictions)\n",
    "    condition = residual < delta\n",
    "    squared_loss = 0.5 * np.square(residual)\n",
    "    linear_loss = delta * (residual - 0.5 * delta)\n",
    "    return np.where(condition, squared_loss, linear_loss).mean()\n",
    "\n",
    "def integrate_system(params, y0, t, N):\n",
    "    beta, gamma = params\n",
    "    result = odeint(deriv, y0, t, args=(N, beta, gamma))\n",
    "    return result\n",
    "\n",
    "def objective_function(params, y0, t, N):\n",
    "    predictions = integrate_system(params, y0, t, N)\n",
    "    S, I, R = predictions.T\n",
    "    cost = (compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e20ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.loc[min(df.index), ['N']].item()\n",
    "y0 = df.loc[min(df.index), ['S']].item(), df.loc[min(df.index), ['I']].item(), df.loc[min(df.index), ['R']].item()\n",
    "initial_guess_for_beta, initial_guess_for_gamma = 0.2, 1./10 \n",
    "days_difference = (max(df['date']) - min(df['date'])).days\n",
    "t = np.linspace(0, days_difference, days_difference + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972b9dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guesses = [initial_guess_for_beta, initial_guess_for_gamma]\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    initial_guesses,\n",
    "    args=(y0, t, N),\n",
    "    method='Nelder-Mead',\n",
    ")\n",
    "optimal_beta, optimal_gamma = result.x\n",
    "print(f\"optimal_beta: {optimal_beta} optimal_gamma: {optimal_gamma}\")\n",
    "print(f\"optimal_beta/optimal_gamma: {optimal_beta/optimal_gamma}\")\n",
    "\n",
    "ret = odeint(deriv, y0, t, args=(N, optimal_beta, optimal_gamma))\n",
    "S, I, R = ret.T\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, df['S']/N, 'b', alpha=0.5, lw=2, label='Susceptible Data')\n",
    "plt.plot(t, df['I']/N, 'r', alpha=0.5, lw=2, label='Infected Data')\n",
    "plt.plot(t, df['R']/N, 'g', alpha=0.5, lw=2, label='Recovered Data')\n",
    "\n",
    "plt.plot(t, S/N, 'b--', alpha=0.5, lw=2, label='Susceptible (Model)')\n",
    "plt.plot(t, I/N, 'r--', alpha=0.5, lw=2, label='Infected (Model)')\n",
    "plt.plot(t, R/N, 'g--', alpha=0.5, lw=2, label='Recovered (Model)')\n",
    "\n",
    "plt.xlabel('Time /days')\n",
    "plt.ylabel('Percentage of Population')\n",
    "plt.tick_params(length=0)\n",
    "plt.grid(True)\n",
    "legend = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"SIR_model_fit_without_lockdown_\" + LOCATION_CHOOSEN + \".eps\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "cost_without_lockdown = compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R)\n",
    "print(f\"cost_without_lockdown: {cost_without_lockdown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db23626",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = optimal_beta/optimal_gamma\n",
    "\n",
    "df[\"S_modelled_without_lockdown\"] = S\n",
    "df[\"I_modelled_without_lockdown\"] = I\n",
    "df[\"R_modelled_without_lockdown\"] = R\n",
    "df[\"r_eff_actual_without_lockdown\"] = r0 * df[\"S\"]/df[\"N\"]\n",
    "df[\"r_eff_modelled_without_lockdown\"] = r0 * df[\"S_modelled_without_lockdown\"]/df[\"N\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df631ce",
   "metadata": {},
   "source": [
    "## With Lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(y, t, N, beta, gamma, lockdown):\n",
    "    S, I, R = y\n",
    "    t = min(int(t), len(lockdown) - 1)  # Ensure t is an integer and within the range of 'lockdown'\n",
    "    dSdt = -beta * (1 - lockdown[int(t)]) * S * I / N\n",
    "    dIdt = beta * (1 - lockdown[int(t)]) * S * I / N - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "def compute_cost(data, predictions):\n",
    "    # mse\n",
    "    return np.square(data - predictions).mean()\n",
    "\n",
    "def compute_cost(data, predictions):\n",
    "    # mae\n",
    "    return np.abs(data - predictions).mean()\n",
    "\n",
    "def compute_cost(data, predictions, delta=1.0):\n",
    "    # Huber loss\n",
    "    residual = np.abs(data - predictions)\n",
    "    condition = residual < delta\n",
    "    squared_loss = 0.5 * np.square(residual)\n",
    "    linear_loss = delta * (residual - 0.5 * delta)\n",
    "    return np.where(condition, squared_loss, linear_loss).mean()\n",
    "\n",
    "def integrate_system(params, y0, t, N, lockdown):\n",
    "    beta, gamma = params\n",
    "    result = odeint(deriv, y0, t, args=(N, beta, gamma, lockdown))\n",
    "    return result\n",
    "\n",
    "def objective_function(params, y0, t, N, lockdown):\n",
    "    predictions = integrate_system(params, y0, t, N, lockdown)\n",
    "    S, I, R = predictions.T\n",
    "    cost = (compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df.loc[min(df.index), ['N']].item()\n",
    "y0 = df.loc[min(df.index), ['S']].item(), df.loc[min(df.index), ['I']].item(), df.loc[min(df.index), ['R']].item()\n",
    "initial_guess_for_beta, initial_guess_for_gamma = 0.2, 1./10 \n",
    "days_difference = (max(df['date']) - min(df['date'])).days\n",
    "t = np.linspace(0, days_difference, days_difference + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb83ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_guesses = [initial_guess_for_beta, initial_guess_for_gamma]\n",
    "lockdown = list(df['stringency_index'].values / 100)\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    initial_guesses,\n",
    "    args=(y0, t, N, lockdown),\n",
    "    method='Nelder-Mead',\n",
    ")\n",
    "optimal_beta, optimal_gamma = result.x\n",
    "print(f\"optimal_beta: {optimal_beta} optimal_gamma: {optimal_gamma}\")\n",
    "print(f\"optimal_beta/optimal_gamma: {optimal_beta/optimal_gamma}\")\n",
    "\n",
    "ret = odeint(deriv, y0, t, args=(N, optimal_beta, optimal_gamma, lockdown))\n",
    "S, I, R = ret.T\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t, df['S']/N, 'b', alpha=0.5, lw=2, label='Susceptible Data')\n",
    "plt.plot(t, df['I']/N, 'r', alpha=0.5, lw=2, label='Infected Data')\n",
    "plt.plot(t, df['R']/N, 'g', alpha=0.5, lw=2, label='Recovered Data')\n",
    "\n",
    "plt.plot(t, S/N, 'b--', alpha=0.5, lw=2, label='Susceptible (Model)')\n",
    "plt.plot(t, I/N, 'r--', alpha=0.5, lw=2, label='Infected (Model)')\n",
    "plt.plot(t, R/N, 'g--', alpha=0.5, lw=2, label='Recovered (Model)')\n",
    "\n",
    "plt.xlabel('Time /days')\n",
    "plt.ylabel('Percentage of Population')\n",
    "plt.tick_params(length=0)\n",
    "plt.grid(True)\n",
    "legend = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"SIR_model_fit_with_lockdown_\" + LOCATION_CHOOSEN + \".eps\"), bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(t, df['stringency_index'], 'c')\n",
    "plt.xlabel('Time /days')\n",
    "plt.ylabel('Stringency Index')\n",
    "plt.grid(True)\n",
    "\n",
    "cost_with_lockdown = compute_cost(df['S'], S) + compute_cost(df['I'], I) + compute_cost(df['R'], R)\n",
    "print(f\"cost_with_lockdown: {cost_with_lockdown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a67735",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, df['I']/N, 'r', alpha=0.5, lw=2, label='Infected Data')\n",
    "plt.plot(t, I/N, 'r--', alpha=0.5, lw=2, label='Infected (Model)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40863839",
   "metadata": {},
   "source": [
    "## Decrease in cost by modelling Lockdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c25ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"difference in cost for with/without lockdown: {cost_without_lockdown - cost_with_lockdown}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b443430",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_values = {\n",
    "    'optimal_beta': optimal_beta,\n",
    "    'optimal_gamma': optimal_gamma\n",
    "}\n",
    "\n",
    "with open(OPTIMAL_VALUES_FILE, \"w\") as outfile: \n",
    "    json.dump(optimal_values, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cbe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79956d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = optimal_beta/optimal_gamma\n",
    "\n",
    "df[\"S_modelled_with_lockdown\"] = S\n",
    "df[\"I_modelled_with_lockdown\"] = I\n",
    "df[\"R_modelled_with_lockdown\"] = R\n",
    "df[\"r_eff_modelled_with_lockdown\"] = r0 * df[\"S_modelled_with_lockdown\"]/df[\"N\"]\n",
    "df[\"r_eff_actual_with_lockdown\"] = r0 * df[\"S\"]/df[\"N\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d7a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(t, df['r_eff_actual_with_lockdown'], 'b', alpha=0.5, lw=2, label='R_eff actual')\n",
    "plt.plot(t, df['r_eff_actual_without_lockdown'], 'b', alpha=0.5, lw=2, label='R_eff actual')\n",
    "plt.plot(t, df['r_eff_modelled_with_lockdown'], 'r', alpha=0.5, lw=2, label='R_eff modelled with lockdown')\n",
    "plt.plot(t, df['r_eff_modelled_without_lockdown'], 'g', alpha=0.5, lw=2, label='R_eff modelled without lockdown')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac0683",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print(1 - cosine(df[\"r_eff_actual_without_lockdown\"], df[\"r_eff_modelled_without_lockdown\"]))\n",
    "print(1 - cosine(df[\"r_eff_actual_with_lockdown\"], df[\"r_eff_modelled_with_lockdown\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringency_data_points = np.arange(0, 100, 0.5)\n",
    "fit_line_loaded = np.poly1d(np.load(STRINGENCY_BASED_GDP))\n",
    "predicted_gdp = fit_line_loaded(stringency_data_points)\n",
    "MIN_GDP = min(predicted_gdp)\n",
    "MAX_GDP = max(predicted_gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df['gdp_normalized']), min(df['gdp_normalized']))\n",
    "\n",
    "df['gdp_min_max_normalized'] = (df['gdp_normalized'] - MIN_GDP) / (MAX_GDP - MIN_GDP)\n",
    "# here modelled means with gdp modelled with stringency\n",
    "df['gdp_normalized_modelled_min_max_normalized'] =  (df['gdp_normalized_modelled'] - MIN_GDP) / (MAX_GDP - MIN_GDP)\n",
    "df.to_csv(os.path.join(DATA_CACHE_DIR, LOCATION_CHOOSEN + \"_merged_data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3aa761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['gdp_min_max_normalized'])\n",
    "plt.plot(df['gdp_normalized_modelled_min_max_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b066f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff()['stringency_index'][1:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stringency_index'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0a658",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_taken = []\n",
    "# \"output/actions_taken/-14154.05.txt\"\n",
    "with open(\"output/actions_taken/-4372.66.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        actions_taken.append(int(line.strip()))\n",
    "start_stringency = 0.0\n",
    "current_stringency_index = start_stringency\n",
    "stringency_index_from_actions_taken = [current_stringency_index]\n",
    "# stringency_index_from_actions_taken = []\n",
    "diff_list = []\n",
    "for action in actions_taken:\n",
    "    reward_inertia_flag = False\n",
    "    if action == 0:\n",
    "        current_stringency_index = max(0, current_stringency_index - 10)\n",
    "        diff = -10\n",
    "    elif action == 1:\n",
    "        current_stringency_index = max(0, current_stringency_index - 5)\n",
    "        diff = -5\n",
    "    elif action == 2:\n",
    "        current_stringency_index = max(0, current_stringency_index - 2.5)\n",
    "        diff = -2.5\n",
    "    elif action == 3:\n",
    "        current_stringency_index = max(0, current_stringency_index + 0)\n",
    "        diff = 0\n",
    "    elif action == 4:\n",
    "        current_stringency_index = min(100, current_stringency_index + 2.5)\n",
    "        diff = 2.5\n",
    "    elif action == 5:\n",
    "        current_stringency_index = min(100, current_stringency_index + 5)\n",
    "        diff = 5\n",
    "    elif action == 6:\n",
    "        current_stringency_index = min(100, current_stringency_index + 10)\n",
    "        diff = 10\n",
    "    stringency_index_from_actions_taken.append(current_stringency_index)\n",
    "    diff_list.append(diff)\n",
    "\n",
    "# stringency_index_from_actions_taken = stringency_index_from_actions_taken + [0]\n",
    "stringency_index_from_actions_taken = np.array(stringency_index_from_actions_taken)\n",
    "\n",
    "# the below is a checking mechanism\n",
    "# stringency_index_from_actions_taken = np.array([0] + list(df['stringency_index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actions_taken[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa6ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_reward_weighted(gdp_normalized_list, r_eff_list):\n",
    "    GDP_WEIGHT = 5 # change this value and see how it affects the reward\n",
    "    reward = []\n",
    "    for i in range(len(gdp_normalized_list)):\n",
    "        if r_eff_list[i] > 1.5:\n",
    "            # When r_eff > 1, the reward is more heavily influenced by the reduction in r_eff\n",
    "            # print(\"before\", gdp_normalized_list[i] / (5 * r_eff_list[i]))\n",
    "            reward.append(gdp_normalized_list[i] / (5 * r_eff_list[i]))\n",
    "        else:\n",
    "            # When r_eff <= 1, the reward is more heavily influenced by the increase in GDP\n",
    "            # print(\"after\", GDP_WEIGHT * gdp_normalized_list[i])\n",
    "            reward.append(GDP_WEIGHT * gdp_normalized_list[i])\n",
    "    return reward\n",
    "\n",
    "def reward_strategy(stringency_moves, reward_strategy_choosen, sir_technique):   \n",
    "    N = df.loc[min(df.index), ['N']].item()\n",
    "    y0 = df.loc[min(df.index), ['S']].item(), df.loc[min(df.index), ['I']].item(), df.loc[min(df.index), ['R']].item()\n",
    "    days_difference = (max(df['date']) - min(df['date'])).days\n",
    "    t = np.linspace(0, days_difference, days_difference + 1)\n",
    "    \n",
    "    stringency_index_random_choice = []\n",
    "    store_S = np.zeros(days_difference + 1)\n",
    "    store_I = np.zeros(days_difference + 1)\n",
    "    store_R = np.zeros(days_difference + 1)\n",
    "\n",
    "    # sir_technique 1 is faster\n",
    "    # 2 is just to check whether the results match with 1\n",
    "    moves_lockdown = stringency_index_from_actions_taken / 100\n",
    "    if sir_technique == 1:\n",
    "        moves_ret = odeint(deriv, y0, t, args=(N, optimal_beta, optimal_gamma, moves_lockdown))\n",
    "        moves_S, moves_I, moves_R = moves_ret.T\n",
    "\n",
    "        df[\"S_moves\"] = moves_S\n",
    "        df[\"I_moves\"] = moves_I\n",
    "        df[\"R_moves\"] = moves_R\n",
    "    elif sir_technique == 2:\n",
    "        for ith_day in range(days_difference + 1):\n",
    "            stringency_index_random_choice.append(stringency_index_from_actions_taken[ith_day])\n",
    "            t = np.linspace(0, ith_day, ith_day + 1)\n",
    "            moves_ret = odeint(deriv, y0, t, args=(N, optimal_beta, optimal_gamma, np.array(stringency_index_random_choice) / 100))\n",
    "            moves_S, moves_I, moves_R = moves_ret.T\n",
    "            store_S[ith_day] = moves_S[-1]\n",
    "            store_I[ith_day] = moves_I[-1]\n",
    "            store_R[ith_day] = moves_R[-1]\n",
    "        df[\"S_moves\"] = store_S\n",
    "        df[\"I_moves\"] = store_I\n",
    "        df[\"R_moves\"] = store_R\n",
    "    \n",
    "    df[\"r_eff_moves_with_lockdown\"] = r0 * df[\"S_moves\"]/df[\"N\"]\n",
    "    df[\"gdp_normalized_moves_min_max_normalized\"] = ((fit_line_loaded(stringency_index_from_actions_taken) - MIN_GDP) / (MAX_GDP - MIN_GDP))[1:]\n",
    "    \n",
    "    modelled_ret = odeint(deriv, y0, t, args=(N, optimal_beta, optimal_gamma, (df['stringency_index']) / 100))\n",
    "    modelled_S, modelled_I, modelled_R = modelled_ret.T\n",
    "    \n",
    "    df[\"S_modelled_with_lockdown_inside_plot\"] = modelled_S\n",
    "    df[\"I_modelled_with_lockdown_inside_plot\"] = modelled_I\n",
    "    df[\"R_modelled_with_lockdown_inside_plot\"] = modelled_R\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df[\"S_modelled_with_lockdown_inside_plot\"], color='b', label='S_modelled')\n",
    "    plt.plot(df[\"I_modelled_with_lockdown_inside_plot\"], color='r', label='I_modelled')\n",
    "    plt.plot(df[\"R_modelled_with_lockdown_inside_plot\"], color='g', label='R_modelled')\n",
    "    plt.plot(df[\"S_moves\"], 'b--', label='S_moves')\n",
    "    plt.plot(df[\"I_moves\"], 'r--', label='I_moves')\n",
    "    plt.plot(df[\"R_moves\"], 'g--', label='R_moves')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('Population')\n",
    "    plt.title('SIR_dynamics')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['stringency_index'], color='b', label='actual')\n",
    "    plt.plot(stringency_index_from_actions_taken , color='g', label='moves')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('stringency')\n",
    "    plt.title('stringency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['r_eff_actual_with_lockdown'], color='b', label='actual')\n",
    "    plt.plot(df['r_eff_modelled_with_lockdown'], color='r', label='modelled')\n",
    "    plt.plot(df['r_eff_moves_with_lockdown'], color='g', label='moves')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('r_eff')\n",
    "    plt.title('R_eff')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['gdp_min_max_normalized'], color='b', label='actual')\n",
    "    plt.plot(df['gdp_normalized_modelled_min_max_normalized'], color='r', label='modelled')\n",
    "    plt.plot(df['gdp_normalized_moves_min_max_normalized'], color='g', label='moves')\n",
    "    plt.xlabel('days')\n",
    "    plt.ylabel('gdp')\n",
    "    plt.title('GDP')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "        \n",
    "    if reward_strategy_choosen == 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df[\"gdp_min_max_normalized\"] / df[\"r_eff_actual_with_lockdown\"], color='b', label='reward(actual) = {reward}'.format(reward = np.sum(df['gdp_min_max_normalized'] / df['r_eff_actual_with_lockdown'])))\n",
    "        plt.plot(df[\"gdp_normalized_modelled_min_max_normalized\"] / df[\"r_eff_modelled_with_lockdown\"], color='r', label='reward(modelled) = {reward}'.format(reward = np.sum(df['gdp_normalized_modelled_min_max_normalized'] / df['r_eff_modelled_with_lockdown'])))\n",
    "        plt.plot(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"], color='g', label='reward(modelled) = {reward}'.format(reward = np.sum(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"])))\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('reward')\n",
    "        plt.title('reward')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df[\"gdp_min_max_normalized\"] / df[\"r_eff_actual_with_lockdown\"], color='b', label='reward(actual) = {reward}'.format(reward = np.sum(df['gdp_min_max_normalized'] / df['r_eff_actual_with_lockdown'])))\n",
    "        plt.plot(df[\"gdp_normalized_modelled_min_max_normalized\"] / df[\"r_eff_modelled_with_lockdown\"], color='r', label='reward(modelled) = {reward}'.format(reward = np.sum(df['gdp_normalized_modelled_min_max_normalized'] / df['r_eff_modelled_with_lockdown'])))\n",
    "        # plt.plot(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"], color='g', label='reward(modelled) = {reward}'.format(reward = np.sum(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"])))\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('reward')\n",
    "        plt.title('reward')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    if reward_strategy_choosen == 2:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        index_to_the_power_of = 0.001\n",
    "        plt.plot(df[\"gdp_min_max_normalized\"] / df[\"r_eff_actual_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='b', label='reward(actual) = {reward}'.format(reward = np.sum(df['gdp_min_max_normalized'] / df['r_eff_actual_with_lockdown'] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        plt.plot(df[\"gdp_normalized_modelled_min_max_normalized\"] / df[\"r_eff_modelled_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='r', label='reward(modelled) = {reward}'.format(reward = np.sum(df['gdp_normalized_modelled_min_max_normalized'] / df['r_eff_modelled_with_lockdown'] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        plt.plot(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='g', label='reward(moves) = {reward}'.format(reward = np.sum(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('reward')\n",
    "        plt.title('reward')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df[\"gdp_min_max_normalized\"] / df[\"r_eff_actual_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='b', label='reward(actual) = {reward}'.format(reward = np.sum(df['gdp_min_max_normalized'] / df['r_eff_actual_with_lockdown'] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        plt.plot(df[\"gdp_normalized_modelled_min_max_normalized\"] / df[\"r_eff_modelled_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='r', label='reward(modelled) = {reward}'.format(reward = np.sum(df['gdp_normalized_modelled_min_max_normalized'] / df['r_eff_modelled_with_lockdown'] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        # plt.plot(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of), color='g', label='reward(moves) = {reward}'.format(reward = np.sum(df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of))))\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('reward')\n",
    "        plt.title('reward')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    if reward_strategy_choosen == 3:\n",
    "        \n",
    "        # we need the epidemic to happen and also the I population to stay below a certain value (beds in the hospital) (10 multiple)\n",
    "        # we need r_eff to be below 1 at an earlier stage (1 multiple)\n",
    "        # we need to reward inertia by a small amount (0.1 multiple)\n",
    "        \n",
    "        hospital_capacity = 0.082\n",
    "        hospital_capacity_reward = -100\n",
    "        # reward_I_percentage = -100 if self.I_proportion >= 0.082 else 0\n",
    "        I_reward_actual = [hospital_capacity_reward if I_percentage >= hospital_capacity else 0 for I_percentage in df[\"I\"] / df[\"N\"]]\n",
    "        I_reward_modelled = [hospital_capacity_reward if I_percentage >= hospital_capacity else 0 for I_percentage in df[\"I_modelled_with_lockdown\"] / N]\n",
    "        I_reward_moves = [hospital_capacity_reward if I_percentage >= hospital_capacity else 0 for I_percentage in df[\"I_moves\"] / N]\n",
    "        \n",
    "        r_eff_reward_choosen = 1\n",
    "        r_eff_punishment_choosen = -1\n",
    "        r_eff_level = 1.8\n",
    "        r_eff_reward_actual = [r_eff_reward_choosen if r_eff <= r_eff_level else r_eff_punishment_choosen for r_eff in df[\"r_eff_actual_with_lockdown\"]]\n",
    "        r_eff_reward_modelled = [r_eff_reward_choosen if r_eff <= r_eff_level else r_eff_punishment_choosen for r_eff in df[\"r_eff_modelled_with_lockdown\"]]\n",
    "        r_eff_reward_moves = [r_eff_reward_choosen if r_eff <= r_eff_level else r_eff_punishment_choosen for r_eff in df[\"r_eff_moves_with_lockdown\"]]\n",
    "        \n",
    "        inertia_rewards_actual = [0] + [abs(diff)*2*-1 for diff in (df['stringency_index'][i] - df['stringency_index'][i - 1] for i in range(1, len(df)))]\n",
    "        # modelled reward for intertia is same as actual\n",
    "        inertia_rewards_modelled = [0] + [abs(diff)*2*-1 for diff in (df['stringency_index'][i] - df['stringency_index'][i - 1] for i in range(1, len(df)))]\n",
    "        inertia_rewards_moves = [abs(diff)*2*-1 for diff in (stringency_index_from_actions_taken[i] - stringency_index_from_actions_taken[i - 1] for i in range(1, len(stringency_index_from_actions_taken)))]\n",
    "        \n",
    "        # index_to_the_power_of = 0.00001\n",
    "        # reward_actual = (df[\"gdp_min_max_normalized\"] / df[\"r_eff_actual_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of)) + I_reward_actual + r_eff_reward_actual + inertia_rewards_actual\n",
    "        # reward_modelled = (df[\"gdp_normalized_modelled_min_max_normalized\"] / df[\"r_eff_modelled_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of)) + I_reward_modelled + r_eff_reward_modelled + inertia_rewards_modelled\n",
    "        # reward_moves = (df[\"gdp_normalized_moves_min_max_normalized\"] / df[\"r_eff_moves_with_lockdown\"] * np.exp(df.index.to_numpy() * index_to_the_power_of)) + I_reward_moves + r_eff_reward_moves + inertia_rewards_moves\n",
    "        \n",
    "        # TODO try this...\n",
    "        \"\"\"\n",
    "        def calculate_reward(gdp_normalized, r_eff_actual):\n",
    "            GDP_WEIGHT = 0.35 # change this value and see how it affects the reward\n",
    "            if r_eff_actual > 1:\n",
    "                # When r_eff > 1, the reward is more heavily influenced by the reduction in r_eff\n",
    "                return gdp_normalized / (5 * r_eff_actual)\n",
    "            else:\n",
    "                # When r_eff <= 1, the reward is more heavily influenced by the increase in GDP\n",
    "                return GDP_WEIGHT * gdp_normalized\n",
    "        \"\"\"\n",
    "        \n",
    "        reward_actual = calculate_reward_weighted(df[\"gdp_min_max_normalized\"], df[\"r_eff_actual_with_lockdown\"]) + I_reward_actual + r_eff_reward_actual + inertia_rewards_actual\n",
    "        reward_modelled = calculate_reward_weighted(df[\"gdp_normalized_modelled_min_max_normalized\"], df[\"r_eff_modelled_with_lockdown\"]) + I_reward_modelled + r_eff_reward_modelled + inertia_rewards_modelled\n",
    "        reward_moves = calculate_reward_weighted(df[\"gdp_normalized_moves_min_max_normalized\"], df[\"r_eff_moves_with_lockdown\"]) + I_reward_moves + r_eff_reward_moves + inertia_rewards_moves\n",
    "        \n",
    "        rl_reward_moves = reward_moves\n",
    "        rl_reward_weighted = calculate_reward_weighted(df[\"gdp_normalized_moves_min_max_normalized\"], df[\"r_eff_moves_with_lockdown\"])\n",
    "        rl_reward_I_percentage = I_reward_moves\n",
    "        rl_reward_r_eff = r_eff_reward_moves\n",
    "        rl_reward_inertia = inertia_rewards_moves\n",
    "\n",
    "        plt.plot(reward_actual, color='b', label='reward(actual) = {reward}'.format(reward = np.sum(reward_actual)))\n",
    "        plt.plot(reward_modelled, color='r', label='reward(modelled) = {reward}'.format(reward = np.sum(reward_modelled)))\n",
    "        plt.plot(reward_moves, color='g', label='reward(moves) = {reward}'.format(reward = np.sum(reward_moves)))\n",
    "        plt.xlabel('days')\n",
    "        plt.ylabel('reward')\n",
    "        plt.title('reward')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        return rl_reward_moves, rl_reward_weighted, rl_reward_I_percentage, rl_reward_r_eff, rl_reward_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6056b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_reward_moves, rl_reward_weighted, rl_reward_I_percentage, rl_reward_r_eff, rl_reward_inertia = reward_strategy(stringency_index_from_actions_taken, reward_strategy_choosen=3, sir_technique=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074adcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for I in df[\"I_modelled_with_lockdown\"] / N:\n",
    "    if I > 0.08:\n",
    "        print(\"yes - 0.08\")\n",
    "\n",
    "for I in df[\"I_modelled_with_lockdown\"] / N:\n",
    "    if I > 0.10:\n",
    "        print(\"yes - 0.10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a993289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df[\"I\"] / df[\"N\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb29c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(df[\"I_modelled_with_lockdown\"] / df[\"N\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174312c0",
   "metadata": {},
   "source": [
    "## Double checking Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c26834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rl_reward_moves, rl_reward_I_percentage, rl_reward_r_eff, rl_reward_inertia, rl_reward_weighted)\n",
    "\n",
    "info_saved_df = pd.read_csv(\"output/info_save/-14233.67.csv\")\n",
    "for i in range(0, 1033):\n",
    "    print(rl_reward_inertia[i], info_saved_df.iloc[i]['reward_inertia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inside_rl:\", np.sum(info_saved_df['reward_inertia']), \"outside_rl:\", np.sum(rl_reward_inertia))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(list(info_saved_df['reward_inertia'][200:350]), 'r', label='inside_rl')\n",
    "plt.plot(list(rl_reward_inertia[200:350]), 'g', label='outside_rl')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e26362",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(info_saved_df['stringency_index'][:150], 'r', label='inside_rl')\n",
    "plt.plot(stringency_index_from_actions_taken[:150], 'g', label='outside_rl')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ed313",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inside_rl:\", np.sum(info_saved_df['reward_r_eff']), \"outside_rl:\",  np.sum(rl_reward_r_eff))\n",
    "plt.plot(info_saved_df['reward_r_eff'][:250], 'r', label='inside_rl')\n",
    "plt.plot(rl_reward_r_eff[:250], 'g', label='outside_rl')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b24cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inside_rl:\", np.sum(info_saved_df['reward_I_percentage']), \"outside_rl:\", np.sum(rl_reward_I_percentage))\n",
    "plt.plot(info_saved_df['reward_I_percentage'][:200], 'r', label='inside_rl')\n",
    "plt.plot(rl_reward_I_percentage[:200], 'g', label='outside_rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inside_rl:\", np.sum(info_saved_df['reward_weigthed']), \"outside_rl:\", np.sum(rl_reward_weighted))\n",
    "plt.plot(info_saved_df['reward_weigthed'][:200], 'r', label='inside_rl')\n",
    "plt.plot(rl_reward_weighted[:200], 'g', label='outside_rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d267427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b144d38e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
